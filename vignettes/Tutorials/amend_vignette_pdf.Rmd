---
title: "AMEND Tutorial"
output: pdf_document
vignette: >
  %\VignetteIndexEntry{AMEND Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!---
To generate 'amend_vignette.Rmd':
  1) Duplicate 'amend_vignette_local.Rmd' and add '.orig' extension to create 'amend_vignette_local.Rmd.orig'
  2) Run this code to locally knit the vignette.
     knitr::knit("/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/AMEND/vignettes/markdown_files/amend_vignette_local.Rmd.orig", 
            output = "/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/AMEND/vignettes/amend_vignette.Rmd")

Resource:
https://ropensci.org/blog/2019/12/08/precompute-vignettes/
--->





# Introduction

A powerful approach for the analysis of omics data is to integrate them with molecular interaction networks. For example, the integration of microarray/RNA-seq data with protein-protein interaction (PPI) networks has emerged as an effective way to elucidate important genes involved in a biological process. These approaches are often called active module identification (AMI) methods and have the goal of finding a subset of genes (either connected or disconnected) in the PPI network that are highly associated with the biological conditions of the experiment.

AMEND is an AMI method that takes as input an interaction network and feature-wise experimental scores (e.g., log fold change) and returns a connected module. AMEND relies on random walk with restart (RWR) and a heuristic solution to the maximum-weight connected subgraph (MWCS) problem to iteratively filter out nodes until an optimal subnetwork is found. At each iteration, the current network is input into RWR, with the feature-wise experimental scores serving as seed values. This produces node weights, which are shifted downwards by a certain quantile (called the filtering rate), resulting in both positive and negative node weights. These weights are used to find a maximum-weight connected subgraph. AMEND uses a heuristic solution first implemented in the [BioNet](https://bioconductor.org/packages/release/bioc/html/BioNet.html) package. This produces a subnetwork, which is the input for the next iteration. Each subnetwork is scored by the product of the mean standardized experimental scores (standardized w.r.t. all nodes in original network) and the mean core-clustering coefficient (a measure of node connectivity). The process stops when there is no change in subnetwork between iterations or when only 2 nodes remain in the subnetwork. The subnetwork with the largest score is returned. 

A key concept in AMEND is the filtering rate, which determines how the untreated RWR scores are shifted before input into the heuristic MWCS solution. The filtering rate is actually a quantile of the untreated RWR scores. As the quantile decreases, each RWR score is subtracted by a smaller number, resulting in fewer negatively weighted nodes, which results in fewer genes filtered out by the MWCS solution. In this sense, the quantile used to shift the untreated RWR scores is a filtering rate. This filtering rate follows an exponential decay schedule, which has two hyperparameters: the starting filtering rate and the decay. 

The decay parameter determines the rate at which the shifting quantile decreases. This value is determined by simulation. The decay is set to the maximum value that will allow the algorithm to arrive at a subnetwork of size $n$. If the decay is too large, the filtering rate will approach zero too quickly. This causes the algorithm to stop early since no nodes will be removed with a filtering rate of zero. The parameter $n$ is set by the user and approximates the size of the final module. 

The primary function is `run_AMEND()`, which implements the AMEND algorithm and returns a connected subnetwork. 

# Installation

AMEND is hosted on [GitHub](https://github.com/samboyd0/AMEND) and can be installed by running the following code.


```r
devtools::install_github("samboyd0/AMEND", build_vignettes = TRUE)
```

# Example 1

This first example will focus on a gene expression microarray experiment to illustrate a typical use case for AMEND. 

## GLUT4 Data Description

The dataset that will be used here is a GLUT4 knockout-overexpression (KO-OX) microarray experiment in mouse adipose tissue and is available on the NCBI's Gene Expression Omnibus under accession [GSE35378](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE35378). GLUT4 is a glucose transporter protein involved in the uptake of glucose into the cell. The experiment involved 4 groups of 3 mice each: GLUT4 KO, KO control, GLUT4 OX, and OX control.  


```r
# Accessing data from NCBI GEO 
gse1 <- GEOquery::getGEO("GSE35378", GSEMatrix = TRUE)
#> Found 1 file(s)
#> GSE35378_series_matrix.txt.gz
#> Using locally cached version: /var/folders/fy/htp6vm7s2y92hk7hh6110p840000gn/T//RtmpUhfgFp/GSE35378_series_matrix.txt.gz
#> Using locally cached version of GPL81 found here:
#> /var/folders/fy/htp6vm7s2y92hk7hh6110p840000gn/T//RtmpUhfgFp/GPL81.soft.gz
data <- Biobase::exprs(gse1[[1]])
head(data)
#>           GSM867144 GSM867145 GSM867146 GSM867147 GSM867148 GSM867149 GSM867150 GSM867151 GSM867152 GSM867153 GSM867154 GSM867155
#> 100001_at     21.92     21.90     31.09     21.90     56.51     26.03    203.10    174.11    153.69    189.57    173.95    223.42
#> 100002_at     58.21     60.57     55.37     76.22     72.60     53.05     58.23     56.80     54.44     69.12     64.58     53.14
#> 100003_at     57.94     60.65     98.07     60.62     63.18     66.61     49.78     37.22    204.64     48.51     76.01     43.02
#> 100004_at    163.94    185.69    202.13    205.00    200.66    207.09    117.30    126.97    144.38    121.94    143.69     72.71
#> 100005_at     56.10     61.13     56.67     73.43     80.79     80.35    447.95    478.10    388.26    403.07    412.29    405.75
#> 100006_at    138.01    188.80    178.50    201.65    156.47    149.67    253.80    244.09    284.08    349.76    292.77    278.73
```

## Equivalent Change Index

AMEND was developed to accommodate a recently introduced metric, the equivalent change index (ECI). The ECI measures the extent to which a gene is equivalently or inversely expressed between two treatment-control comparisons. It ranges between -1 and 1, with a value of -1 indicating changes in expression in exactly opposing ways (e.g., expression was halved between groups for one experiment but doubled for the other), and a value of 1 indicating changes in expression in exactly equivalent ways (e.g., expression was doubled between groups for both experiments). Formally, the ECI for gene $i$ is $$\lambda_i=sign(\beta_{i1}*\beta_{i2})\frac{min(|\beta_{i1}|,|\beta_{i2}|)}{max(|\beta_{i1}|,|\beta_{i2}|)}(1-max(p_{i1}, p_{i2}))$$ where $\beta_{ij}$ represents the log fold change and $p_{ij}$ the p-value for gene $i$ from experiment $j$. 

## Differential Expression Analysis 

This section will show the steps taken to generate the log fold changes and ECIs for the GLUT4 dataset. Preprocessing involves background subtracting and normalizing, as well as checking for zero sample variances. 


```r
# Background-subtracting and normalizing with oligo package
re <- oligo::basicRMA(data, row.names(data))
#> Background correcting
#> Normalizing
#> Calculating Expression

# checking for genes with zero sample variance
r <- matrix()
for(i in 1:nrow(re)){
  t <- sd(re[i,])
  if(t == 0){
    r <- c(r, i)
  }
}
var_check <- r[-1]
```

Next, the _limma_ package is used to fit linear models to the expression data. $log_2$ fold changes are obtained for the appropriate group comparisons, along with their unadjusted p-values. 


```r
# Design matrix
groups = c(rep("OX", 3), rep("OX_ctrl", 3), rep("KO", 3), rep("KO_ctrl", 3))
X = stats::model.matrix(~0+groups)
colnames(X) = sort(unique(groups))

# Fitting linear models
fit <- limma::lmFit(re[-var_check,], design = X)

# Getting contrast coefficents for KO vs. Ctrl 1
cnt_KO = limma::makeContrasts(contrasts = "KO-KO_ctrl", levels = colnames(X))
fit_KO = limma::contrasts.fit(fit, contrasts = cnt_KO)
fit_KO <- limma::eBayes(fit_KO)
tt_KO <- limma::topTable(fit_KO, number = 100000, adjust.method = "BH")
esize_KO <- tt_KO$logFC
pval_KO <- tt_KO$P.Value
names(esize_KO) <- row.names(tt_KO)
names(pval_KO) <- row.names(tt_KO)
head(esize_KO)
#>  93109_f_at 101565_f_at 101574_f_at 101572_f_at   101828_at   102635_at 
#>    1.850815    2.375126    2.405287    1.998683    1.605275   -1.792900

# Getting contrast coefficents for OX vs. Ctrl 2
cnt_OX = limma::makeContrasts(contrasts = "OX-OX_ctrl", levels = colnames(X))
fit_OX = limma::contrasts.fit(fit, contrasts = cnt_OX)
fit_OX <- limma::eBayes(fit_OX)
tt_OX <- limma::topTable(fit_OX, number = 100000, adjust.method = "BH")
esize_OX <- tt_OX$logFC
pval_OX <- tt_OX$P.Value
names(esize_OX) <- row.names(tt_OX)
names(pval_OX) <- row.names(tt_OX)
head(esize_OX)
#>   104424_at    97752_at   101473_at 101638_s_at  95339_r_at    93996_at 
#>    2.943478    2.333525   -1.434809   -3.940409    1.717504   -1.433025
```

We are now able to calculate the ECIs for each probe in the microarray experiment using the R package _ECEA_, which can be installed from [GitHub](https://github.com/jeffreyat/ECEA) with the following code: `devtools::install_github("jeffreyat/ECEA")`. 


```r
# Getting ECI values for each gene
eci <- ECEA::getECI(smd1 = esize_OX, smd2 = esize_KO, p1 = pval_OX, p2 = pval_KO)
eci <- data.frame(ECI = eci, row.names = names(eci))
```

The probe IDs are now mapped to gene symbols. Along with the ECI, we will also extract the $log_2$ fold changes for the GLUT4 KO vs. Control groups for downstream analysis.


```r
# Mapping probe identifier to gene symbol & aggregating ECI values and logFC values for KO vs. Ctrl
datFC = data.frame(logFC = tt_KO$logFC * (1 - tt_KO$P.Value), row.names = row.names(tt_KO))
dat <- eci
sym_map <- mgu74av2.db::mgu74av2SYMBOL

# Map the probes
genes <- unlist(as.list(sym_map[rownames(dat)]))

# Remove probes that didn't map
genes <- na.omit(genes)
common <- intersect(names(genes), rownames(dat))
genes <- genes[common]
dat <- dat[common,]
datFC = datFC[common,]

# Aggregate probes... take median ECI if multiple probes map to same gene
dat <- aggregate(dat, by = list(genes), FUN = median)
names(dat) <- c("Gene", "ECI")
row.names(dat) <- dat$Gene
dat <- dat %>% dplyr::select(-Gene)

# Aggregate probes... take median logFC if multiple probes map to same gene
datFC <- aggregate(datFC, by = list(genes), FUN = median)
names(datFC) <- c("Gene", "logFC")
row.names(datFC) <- datFC$Gene
datFC <- datFC %>% dplyr::select(-Gene)
```


## Protein-Protein Interaction Network

For this example, a _mus musculus_ PPI network is downloaded from STRING (v11.0). Edges appear twice in the downloaded file, necessitating a helper function to remove the duplicate edges. Only interactions with a confidence score $\ge$ 0.8 are kept.


```r
# Getting mapping between Mouse Gene Symbols <--> Ensembl Peptide IDs
gene_symbols <- row.names(dat)
# ensembl <- biomaRt::useMart("ensembl", dataset = "mmusculus_gene_ensembl")
ensembl <- biomaRt::useMart("ensembl", dataset = "mmusculus_gene_ensembl", host = "https://feb2023.archive.ensembl.org")
mapping <- biomaRt::getBM(attributes=c("mgi_symbol", "ensembl_peptide_id"),
                          filters = "mgi_symbol",
                          values = gene_symbols,
                          mart = ensembl)
mapping <- mapping %>% dplyr::filter(ensembl_peptide_id != "")

# Function for removing the duplicate edges from String PPI network 
remove_duplicate_edges = function(x){
  g = igraph::graph_from_edgelist(as.matrix(x[,1:2]), directed = F)
  igraph::E(g)$weight = x[,3] / 1000
  adjM = as.matrix(igraph::as_adjacency_matrix(g, attr = "weight", sparse = T)) / 2
  g = igraph::graph_from_adjacency_matrix(adjM, mode = "undirected", weighted = TRUE)
  el = igraph::as_edgelist(g)
  return(cbind(el, igraph::E(g)$weight))
}

# Loading in mus musculus PPIN from String v11.0... 
# Can be downloaded from STRING website, but make sure you're on the right version
file_path = "/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/10090.protein.links.v11.0.txt.gz"
ppi = data.table::fread(file = file_path,
                        header = TRUE, sep = " ") %>%
  dplyr::filter(combined_score >= 800) %>%
  dplyr::mutate(protein1 = do.call(c, lapply(strsplit(protein1, "\\."), function(x) x[2])),
         protein2 = do.call(c, lapply(strsplit(protein2, "\\."), function(x) x[2])))  %>%
  as.data.frame() %>%
  remove_duplicate_edges()
#> Warning in asMethod(object): sparse->dense coercion: allocating vector of size 1.4 GiB
head(ppi)
#>      [,1]                 [,2]                 [,3]   
#> [1,] "ENSMUSP00000000001" "ENSMUSP00000017460" "0.9"  
#> [2,] "ENSMUSP00000000001" "ENSMUSP00000039107" "0.917"
#> [3,] "ENSMUSP00000000001" "ENSMUSP00000052894" "0.916"
#> [4,] "ENSMUSP00000000001" "ENSMUSP00000025842" "0.904"
#> [5,] "ENSMUSP00000000001" "ENSMUSP00000045335" "0.916"
#> [6,] "ENSMUSP00000000001" "ENSMUSP00000126191" "0.916"
```

Not all genes will map to a protein in the PPI network. Conversely, some proteins won't correspond to a gene in the experiment. Only genes and proteins that have a mapping will be kept, thus ensuring that each node in the network has an experimental score (e.g., ECI or log fold change).


```r
# Keeping only genes that map to a protein in PPIN
mapping = mapping %>%
  dplyr::mutate(ppi = ensembl_peptide_id %in% ppi[,1] | ensembl_peptide_id %in% ppi[,2]) %>%
  dplyr::filter(ppi) %>%
  dplyr::group_by(mgi_symbol) %>%
  dplyr::filter(row_number() == 1) %>%
  as.data.frame()

# Keeping only proteins that map to a gene in the experiment
ppi = ppi[ppi[,1] %in% mapping$ensembl_peptide_id & ppi[,2] %in% mapping$ensembl_peptide_id,]
```

The input network for AMEND is required to be connected, so we will take the largest connected component. The ECIs and $log_2$ fold changes are then set as vertex attributes. 


```r
# Getting largest connected component of PPIN as an igraph object
glut4_graph = igraph::graph_from_edgelist(as.matrix(ppi[,1:2]), directed = FALSE)
igraph::E(glut4_graph)$weight = as.numeric(ppi[,3])
igraph::V(glut4_graph)$symbol = mapping$mgi_symbol[match(igraph::V(glut4_graph)$name, mapping$ensembl_peptide_id)]
if(!igraph::is_connected(glut4_graph)){
  l = igraph::decompose(glut4_graph)
  glut4_graph = l[[which.max(do.call(c, lapply(l, igraph::vcount)))]]
}

# Setting vertex attribute ECI and logFC (logFC for KO vs. Ctrl)
igraph::V(glut4_graph)$ECI = dat$ECI[match(igraph::V(glut4_graph)$symbol, row.names(dat))]
igraph::V(glut4_graph)$logFC = datFC$logFC[match(igraph::V(glut4_graph)$symbol, row.names(datFC))]
glut4_graph
#> IGRAPH ea59658 UNW- 6487 124359 -- 
#> + attr: name (v/c), symbol (v/c), ECI (v/n), logFC (v/n), weight (e/n)
#> + edges from ea59658 (vertex names):
#>  [1] ENSMUSP00000000001--ENSMUSP00000017460 ENSMUSP00000000001--ENSMUSP00000039107 ENSMUSP00000000001--ENSMUSP00000052894 ENSMUSP00000000001--ENSMUSP00000025842
#>  [5] ENSMUSP00000000001--ENSMUSP00000045335 ENSMUSP00000000001--ENSMUSP00000093978 ENSMUSP00000000001--ENSMUSP00000040847 ENSMUSP00000000001--ENSMUSP00000066822
#>  [9] ENSMUSP00000000001--ENSMUSP00000076155 ENSMUSP00000000001--ENSMUSP00000052444 ENSMUSP00000000001--ENSMUSP00000052581 ENSMUSP00000000001--ENSMUSP00000053489
#> [13] ENSMUSP00000000001--ENSMUSP00000028883 ENSMUSP00000000001--ENSMUSP00000045911 ENSMUSP00000000001--ENSMUSP00000137518 ENSMUSP00000000001--ENSMUSP00000047586
#> [17] ENSMUSP00000000001--ENSMUSP00000068731 ENSMUSP00000000001--ENSMUSP00000024004 ENSMUSP00000000001--ENSMUSP00000005406 ENSMUSP00000000001--ENSMUSP00000065799
#> [21] ENSMUSP00000000001--ENSMUSP00000031146 ENSMUSP00000000001--ENSMUSP00000074885 ENSMUSP00000000001--ENSMUSP00000038884 ENSMUSP00000000001--ENSMUSP00000065000
#> [25] ENSMUSP00000000001--ENSMUSP00000053638 ENSMUSP00000000001--ENSMUSP00000019074 ENSMUSP00000000001--ENSMUSP00000093311 ENSMUSP00000000001--ENSMUSP00000063136
#> [29] ENSMUSP00000000001--ENSMUSP00000127024 ENSMUSP00000000001--ENSMUSP00000047646 ENSMUSP00000000001--ENSMUSP00000063986 ENSMUSP00000000001--ENSMUSP00000030815
#> + ... omitted several edges
```

`run_AMEND()` can also work with an adjacency matrix and a vector of node scores, instead of a graph.


```r
# Getting adjacency matrix from graph
glut4_adjM = igraph::as_adjacency_matrix(glut4_graph, attr = "weight", sparse = T)
glut4_adjM[1:6,1:6]
#> 6 x 6 sparse Matrix of class "dgCMatrix"
#>                    ENSMUSP00000000001 ENSMUSP00000017460 ENSMUSP00000039107 ENSMUSP00000052894 ENSMUSP00000025842 ENSMUSP00000045335
#> ENSMUSP00000000001              .                  0.900              0.917              0.916              0.904              0.916
#> ENSMUSP00000017460              0.900              .                  0.901              0.901              0.932              0.901
#> ENSMUSP00000039107              0.917              0.901              .                  0.908              0.905              0.900
#> ENSMUSP00000052894              0.916              0.901              0.908              .                  0.906              0.901
#> ENSMUSP00000025842              0.904              0.932              0.905              0.906              .                  0.905
#> ENSMUSP00000045335              0.916              0.901              0.900              0.901              0.905              .

# Creating named vectors of gene-wise experimental scores
eci_scores = igraph::V(glut4_graph)$ECI
logFC_KO = igraph::V(glut4_graph)$logFC
names(eci_scores) = names(logFC_KO) = igraph::V(glut4_graph)$name
head(eci_scores)
#> ENSMUSP00000000001 ENSMUSP00000017460 ENSMUSP00000039107 ENSMUSP00000052894 ENSMUSP00000025842 ENSMUSP00000045335 
#>       0.0053260160      -0.1573755452      -0.0666034318       0.3836840933       0.0127265124      -0.0009255554
head(logFC_KO)
#> ENSMUSP00000000001 ENSMUSP00000017460 ENSMUSP00000039107 ENSMUSP00000052894 ENSMUSP00000025842 ENSMUSP00000045335 
#>       0.0004979644      -0.1002514365       0.0091279150       0.1068692232      -0.1118967908      -0.0078257876
```

## Running AMEND with ECI

Now that we have analyzed our microarray data and obtained a PPI network, we can continue with the active module identification step. It is important to clarify the biological question of interset that we want to answer. For the GLUT4 KO-OX experiment, it may be of interest to know which genes are affected in opposing ways by the two treatments. A gene that is up-regulated in the KO-control arm and down-regulated in the OX-control arm suggests a close association of that gene with GLUT4.
The ECI is well suited to answer this type of question. Since we are interested in inversely regulated genes, we will want to set `data = "ECI"`, `FUN = "shift_scale"`, and `FUN.params = list(DOI = -1, w = 0.5)`. The `FUN = "shift_scale"` argument is meant for data types that are centered about 0. As the name implies, it shifts all values to their absolute value and then scales input values that weren't in the direction of interest (_DOI_) by a certain factor _w_, thus transforming the input into all non-negative values. We will set `n = 25` to specify the approximate size of the final module.

The `normalize` argument specifies how to normalize the adjacency matrix for random walk with restart (RWR). `normalize = "degree"` will column normalize the adjacency matrix using node degree. The other option, `normalize = "modified_degree"`, first modifies the adjacency matrix by left and right multiplying by a diagonal matrix whose elements are the node degrees raised to the power $-k$: $A^{\prime}=D^{-k}AD^{-k}$. The resulting symmetric matrix is then column-normalized as usual. This approach penalizes edge weights in proportion to the product of the degrees of its adjacent nodes, leading to reduced transition probabilities __to__ a target node in proportion to that target node's degree. One can also view this approach as a biased random walk. Since the modified adjacency matrix is column-normalized, the values from the right diagonal matrix cancel out, thus one can obtain the same transition matrix by only left-multiplying the original adjacency matrix by the diagonal matrix described above ($A^{\prime}=D^{-k}A$) and then column-normalizing. The node attribute values used for this biased random walk are then $d^{-k}_{i}$ for node $i$. `normalize = "modified_degree"` is one way to reduce the influence of degree on diffusion scores.


```r
# Using the igraph object as input
module = run_AMEND(graph = glut4_graph, n = 25, data = "ECI", FUN = "shift_scale", 
                   FUN.params = list(DOI = -1, w = 0.5), normalize = "degree")
#> *** Converged! *** ID=1

# Can also use the adjacency matrix and vector of node scores
if(0){
  module = run_AMEND(adj_matrix = glut4_adjM, data = eci_scores, n = 25, FUN = "shift_scale", 
                   FUN.params = list(DOI = -1, w = 0.5), normalize = "degree")
}
```

Let's inspect the module returned by `run_AMEND()`. A named list is returned containing the final module, module score, a list of node names contained in the intermediate subnetworks, network statistics for all iterations, the runtime, and a list of the input parameters. 


```r
# The final module
module$module
#> IGRAPH 05b2276 UNW- 48 71 -- 
#> + attr: name (v/c), symbol (v/c), ECI (v/n), logFC (v/n), node_type (v/c), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from 05b2276 (vertex names):
#>  [1] ENSMUSP00000076155--ENSMUSP00000047586 ENSMUSP00000076155--ENSMUSP00000047646 ENSMUSP00000047586--ENSMUSP00000047646 ENSMUSP00000076155--ENSMUSP00000058040
#>  [5] ENSMUSP00000047586--ENSMUSP00000058040 ENSMUSP00000047646--ENSMUSP00000058040 ENSMUSP00000076155--ENSMUSP00000024988 ENSMUSP00000047586--ENSMUSP00000024988
#>  [9] ENSMUSP00000047646--ENSMUSP00000024988 ENSMUSP00000058040--ENSMUSP00000024988 ENSMUSP00000033131--ENSMUSP00000021141 ENSMUSP00000021141--ENSMUSP00000139275
#> [13] ENSMUSP00000033131--ENSMUSP00000059889 ENSMUSP00000076155--ENSMUSP00000021346 ENSMUSP00000047586--ENSMUSP00000021346 ENSMUSP00000024988--ENSMUSP00000086795
#> [17] ENSMUSP00000024988--ENSMUSP00000032825 ENSMUSP00000086795--ENSMUSP00000032825 ENSMUSP00000076155--ENSMUSP00000027812 ENSMUSP00000024988--ENSMUSP00000041250
#> [21] ENSMUSP00000024988--ENSMUSP00000065393 ENSMUSP00000041250--ENSMUSP00000065393 ENSMUSP00000065393--ENSMUSP00000095316 ENSMUSP00000047646--ENSMUSP00000028259
#> [25] ENSMUSP00000047646--ENSMUSP00000032198 ENSMUSP00000028259--ENSMUSP00000032198 ENSMUSP00000095316--ENSMUSP00000115578 ENSMUSP00000115578--ENSMUSP00000104298
#> [29] ENSMUSP00000115578--ENSMUSP00000018875 ENSMUSP00000070019--ENSMUSP00000018875 ENSMUSP00000139275--ENSMUSP00000030797 ENSMUSP00000115578--ENSMUSP00000030797
#> + ... omitted several edges

# data.frame of network stats for all iterations
module$stats
#>    Decay Restart parameter Network score Avg Z Avg CCC Nodes Edges Density Filtering rate Observed filtering rate
#> 1   0.16              0.95         0.862 1.002   0.861  2202 18005   0.007          0.627                   0.661
#> 2   0.16              0.95         1.515 1.759   0.861   892  4380   0.011          0.535                   0.595
#> 3   0.16              0.95         2.006 2.334   0.859   417  1305   0.015          0.456                   0.533
#> 4   0.17              0.90         2.349 2.758   0.852   240   602   0.021          0.384                   0.424
#> 5   0.18              0.95         2.605 3.046   0.855   146   307   0.029          0.321                   0.392
#> 6   0.18              0.90         2.776 3.283   0.846   102   194   0.038          0.268                   0.301
#> 7   0.19              0.90         2.919 3.467   0.842    65   106   0.051          0.222                   0.363
#> 8   0.20              0.95         3.067 3.559   0.862    54    84   0.059          0.182                   0.169
#> 9   0.23              0.90         3.100 3.569   0.869    48    71   0.063          0.144                   0.111
#> 10  0.23              0.90         3.094 3.571   0.866    47    70   0.065          0.115                   0.021

# Runtime
module$time
#> Time difference of 1.542686 mins
```

## Running AMEND with log fold change 

AMEND can also accommodate log fold changes. We have log fold changes for the GLUT4 KO vs. control DE analysis. Suppose we are interested in genes with large log fold changes, regardless of direction. Then we would set `data = "logFC"`, `FUN = "exp"`, and `FUN.params = list(DOI = 0)`.


```r
# Using the igraph object as input
module2 = run_AMEND(graph = glut4_graph, n = 25, data = "logFC", FUN = "exp", 
                   FUN.params = list(DOI = 0), normalize = "degree")
#> *** Converged! *** ID=1

# Can also use the adjacency matrix and vector of node scores
if(0){
  module2 = run_AMEND(adj_matrix = glut4_adjM, n = 25, data = logFC_KO, FUN = "exp", 
                   FUN.params = list(DOI = 0), normalize = "degree")
}
```

Here are the results. 


```r
# The final module
module2$module
#> IGRAPH 5435abb UNW- 15 20 -- 
#> + attr: name (v/c), symbol (v/c), ECI (v/n), logFC (v/n), node_type (v/c), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from 5435abb (vertex names):
#>  [1] ENSMUSP00000053489--ENSMUSP00000001008 ENSMUSP00000053489--ENSMUSP00000001780 ENSMUSP00000108367--ENSMUSP00000093101 ENSMUSP00000053489--ENSMUSP00000026845
#>  [5] ENSMUSP00000001008--ENSMUSP00000026845 ENSMUSP00000001780--ENSMUSP00000026845 ENSMUSP00000108367--ENSMUSP00000026845 ENSMUSP00000093101--ENSMUSP00000026845
#>  [9] ENSMUSP00000079380--ENSMUSP00000032203 ENSMUSP00000093101--ENSMUSP00000032203 ENSMUSP00000026845--ENSMUSP00000017799 ENSMUSP00000079380--ENSMUSP00000004986
#> [13] ENSMUSP00000017799--ENSMUSP00000107214 ENSMUSP00000079124--ENSMUSP00000107214 ENSMUSP00000001780--ENSMUSP00000022592 ENSMUSP00000108367--ENSMUSP00000022592
#> [17] ENSMUSP00000026845--ENSMUSP00000022592 ENSMUSP00000017799--ENSMUSP00000022592 ENSMUSP00000001780--ENSMUSP00000073695 ENSMUSP00000026845--ENSMUSP00000092492

# data.frame of network stats for all iterations
module2$stats
#>    Decay Restart parameter Network score  Avg Z Avg CCC Nodes Edges Density Filtering rate Observed filtering rate
#> 1   0.16              0.95         0.288  0.333   0.864  2336 30460   0.011          0.627                   0.640
#> 2   0.16              0.95         0.680  0.795   0.855  1023  6386   0.012          0.535                   0.562
#> 3   0.16              0.90         1.140  1.338   0.852   529  2803   0.020          0.456                   0.483
#> 4   0.16              0.90         1.691  1.961   0.862   312  1367   0.028          0.388                   0.410
#> 5   0.16              0.95         2.292  2.667   0.859   191   492   0.027          0.331                   0.388
#> 6   0.16              0.80         2.850  3.328   0.856   140   366   0.038          0.282                   0.267
#> 7   0.17              0.75         3.397  4.003   0.849   104   257   0.048          0.238                   0.257
#> 8   0.16              0.90         3.903  4.643   0.841    84   155   0.044          0.203                   0.192
#> 9   0.17              0.80         4.411  5.262   0.838    68   121   0.053          0.171                   0.190
#> 10  0.17              0.70         4.779  5.714   0.836    59   106   0.062          0.144                   0.132
#> 11  0.14              0.80         5.053  6.100   0.828    52    86   0.065          0.125                   0.119
#> 12  0.15              0.95         5.483  6.506   0.843    41    67   0.082          0.108                   0.212
#> 13  0.16              0.30         5.676  6.799   0.835    37    62   0.093          0.092                   0.098
#> 14  0.20              0.80         5.978  7.199   0.830    34    54   0.096          0.075                   0.081
#> 15  0.20              0.20         6.124  7.475   0.819    31    51   0.110          0.062                   0.088
#> 16  0.21              0.65         6.459  7.882   0.819    29    45   0.111          0.050                   0.065
#> 17  0.26              0.35         6.512  8.146   0.799    27    42   0.120          0.039                   0.069
#> 18  0.26              0.20         6.788  8.405   0.808    26    41   0.126          0.030                   0.037
#> 19  0.53              0.50         7.063  8.650   0.817    25    40   0.133          0.017                   0.038
#> 20  1.00              0.65         7.211  8.947   0.806    24    37   0.134          0.006                   0.040
#> 21  1.00              0.35         7.312  9.101   0.803    23    36   0.142          0.002                   0.042
#> 22  1.00              0.35         7.532  9.256   0.814    22    35   0.152          0.001                   0.043
#> 23  1.00              0.30         7.715  9.499   0.812    21    34   0.162          0.000                   0.045
#> 24  1.00              0.50         7.842  9.627   0.815    20    33   0.174          0.000                   0.048
#> 25  1.00              0.50         7.980  9.753   0.818    19    32   0.187          0.000                   0.050
#> 26  1.00              0.55         8.040 10.191   0.789    18    27   0.176          0.000                   0.053
#> 27  1.00              0.50         8.119 10.415   0.780    17    25   0.184          0.000                   0.056
#> 28  1.00              0.20         8.141 10.466   0.778    16    24   0.200          0.000                   0.059
#> 29  1.00              0.45         8.546 11.129   0.768    15    20   0.190          0.000                   0.062

# Runtime
module2$time
#> Time difference of 2.094296 mins
```

Suppose that we want to investigate an intermediate subnetwork that was generated during `run_AMEND()`, either because the final module was too small or because we want to see which genes were filtered out. From the output of `module2$stats`, let's choose the subnetwork from iteration 6. We can retrieve this subnetwork by using the function `get_subnetwork()`. We can also look at the nodes in this subnetwork directly from the `module2` object.


```r
# Using get_subnetwork()
subnet6 = get_subnetwork(ig = glut4_graph, amend_object = module2, k = 6)
subnet6
#> IGRAPH 46278c4 UNW- 140 366 -- 
#> + attr: name (v/c), symbol (v/c), ECI (v/n), logFC (v/n), weight (e/n)
#> + edges from 46278c4 (vertex names):
#>  [1] ENSMUSP00000053489--ENSMUSP00000047586 ENSMUSP00000053489--ENSMUSP00000024004 ENSMUSP00000047586--ENSMUSP00000024004 ENSMUSP00000053489--ENSMUSP00000065799
#>  [5] ENSMUSP00000047586--ENSMUSP00000065799 ENSMUSP00000024004--ENSMUSP00000065799 ENSMUSP00000053489--ENSMUSP00000074885 ENSMUSP00000047586--ENSMUSP00000074885
#>  [9] ENSMUSP00000024004--ENSMUSP00000074885 ENSMUSP00000065799--ENSMUSP00000074885 ENSMUSP00000053489--ENSMUSP00000099423 ENSMUSP00000047586--ENSMUSP00000099423
#> [13] ENSMUSP00000024004--ENSMUSP00000099423 ENSMUSP00000065799--ENSMUSP00000099423 ENSMUSP00000074885--ENSMUSP00000099423 ENSMUSP00000053489--ENSMUSP00000026911
#> [17] ENSMUSP00000047586--ENSMUSP00000026911 ENSMUSP00000024004--ENSMUSP00000026911 ENSMUSP00000065799--ENSMUSP00000026911 ENSMUSP00000074885--ENSMUSP00000026911
#> [21] ENSMUSP00000099423--ENSMUSP00000026911 ENSMUSP00000053489--ENSMUSP00000052185 ENSMUSP00000047586--ENSMUSP00000052185 ENSMUSP00000024004--ENSMUSP00000052185
#> [25] ENSMUSP00000065799--ENSMUSP00000052185 ENSMUSP00000074885--ENSMUSP00000052185 ENSMUSP00000099423--ENSMUSP00000052185 ENSMUSP00000026911--ENSMUSP00000052185
#> [29] ENSMUSP00000053489--ENSMUSP00000083656 ENSMUSP00000047586--ENSMUSP00000083656 ENSMUSP00000024004--ENSMUSP00000083656 ENSMUSP00000065799--ENSMUSP00000083656
#> + ... omitted several edges

# Directly from module2
module2$subnetworks[[6]]
#>   [1] "ENSMUSP00000053489" "ENSMUSP00000047586" "ENSMUSP00000024004" "ENSMUSP00000065799" "ENSMUSP00000074885" "ENSMUSP00000099423" "ENSMUSP00000026911" "ENSMUSP00000052185" "ENSMUSP00000083656"
#>  [10] "ENSMUSP00000025912" "ENSMUSP00000000193" "ENSMUSP00000001008" "ENSMUSP00000079380" "ENSMUSP00000092393" "ENSMUSP00000032520" "ENSMUSP00000064255" "ENSMUSP00000029400" "ENSMUSP00000028681"
#>  [19] "ENSMUSP00000056774" "ENSMUSP00000033730" "ENSMUSP00000031172" "ENSMUSP00000132166" "ENSMUSP00000049852" "ENSMUSP00000001780" "ENSMUSP00000073875" "ENSMUSP00000043376" "ENSMUSP00000036044"
#>  [28] "ENSMUSP00000108367" "ENSMUSP00000093101" "ENSMUSP00000046530" "ENSMUSP00000001927" "ENSMUSP00000026845" "ENSMUSP00000130979" "ENSMUSP00000030044" "ENSMUSP00000021506" "ENSMUSP00000074810"
#>  [37] "ENSMUSP00000032203" "ENSMUSP00000014578" "ENSMUSP00000020161" "ENSMUSP00000028466" "ENSMUSP00000090884" "ENSMUSP00000007253" "ENSMUSP00000099889" "ENSMUSP00000025691" "ENSMUSP00000017799"
#>  [46] "ENSMUSP00000097547" "ENSMUSP00000115578" "ENSMUSP00000031280" "ENSMUSP00000108485" "ENSMUSP00000102009" "ENSMUSP00000032201" "ENSMUSP00000112765" "ENSMUSP00000000369" "ENSMUSP00000004986"
#>  [55] "ENSMUSP00000019362" "ENSMUSP00000126092" "ENSMUSP00000030212" "ENSMUSP00000034602" "ENSMUSP00000075074" "ENSMUSP00000098256" "ENSMUSP00000059270" "ENSMUSP00000027601" "ENSMUSP00000079124"
#>  [64] "ENSMUSP00000071989" "ENSMUSP00000134388" "ENSMUSP00000020969" "ENSMUSP00000024727" "ENSMUSP00000055427" "ENSMUSP00000107247" "ENSMUSP00000117616" "ENSMUSP00000075250" "ENSMUSP00000107214"
#>  [73] "ENSMUSP00000039844" "ENSMUSP00000097294" "ENSMUSP00000088287" "ENSMUSP00000056604" "ENSMUSP00000124719" "ENSMUSP00000034973" "ENSMUSP00000020991" "ENSMUSP00000002663" "ENSMUSP00000025249"
#>  [82] "ENSMUSP00000140676" "ENSMUSP00000062096" "ENSMUSP00000029674" "ENSMUSP00000030714" "ENSMUSP00000063562" "ENSMUSP00000045945" "ENSMUSP00000095199" "ENSMUSP00000022592" "ENSMUSP00000109633"
#>  [91] "ENSMUSP00000041282" "ENSMUSP00000107717" "ENSMUSP00000023559" "ENSMUSP00000079670" "ENSMUSP00000033761" "ENSMUSP00000067325" "ENSMUSP00000087756" "ENSMUSP00000044624" "ENSMUSP00000028836"
#> [100] "ENSMUSP00000058629" "ENSMUSP00000088453" "ENSMUSP00000027067" "ENSMUSP00000026050" "ENSMUSP00000105527" "ENSMUSP00000070983" "ENSMUSP00000099863" "ENSMUSP00000064947" "ENSMUSP00000022496"
#> [109] "ENSMUSP00000028921" "ENSMUSP00000018767" "ENSMUSP00000109337" "ENSMUSP00000078715" "ENSMUSP00000093644" "ENSMUSP00000007005" "ENSMUSP00000088249" "ENSMUSP00000002818" "ENSMUSP00000068123"
#> [118] "ENSMUSP00000120528" "ENSMUSP00000101159" "ENSMUSP00000030551" "ENSMUSP00000110118" "ENSMUSP00000073695" "ENSMUSP00000083908" "ENSMUSP00000092492" "ENSMUSP00000026552" "ENSMUSP00000129378"
#> [127] "ENSMUSP00000034811" "ENSMUSP00000102636" "ENSMUSP00000025511" "ENSMUSP00000097150" "ENSMUSP00000001824" "ENSMUSP00000000924" "ENSMUSP00000027989" "ENSMUSP00000116259" "ENSMUSP00000036971"
#> [136] "ENSMUSP00000033715" "ENSMUSP00000073541" "ENSMUSP00000046856" "ENSMUSP00000080531" "ENSMUSP00000041294"
```

# Extensions

## Heterogeneous/Multiplex Networks

A network is heterogeneous if it contains more than one node type, with the different parts of the network corresponding to these node types called _components_. Traditionally, a network is defined as multiplex if, for the same node type, there is more than one edge type, resulting in different parts of the network called _layers_,  which are connected by linking common nodes between layers. However, this definition can be extended to include multiple data types as well, thus allowing one to integrate multiple data types for the same node type. Heterogeneous-multiplex networks give us a means to create increasingly complex and realistic models of biological systems through the integration of different omics types in the same analytic object.

Previously, RWR has been generalized to heterogeneous-monoplex networks ([Li et al.](https://doi.org/10.1093/bioinformatics/btq108)), heterogeneous-multiplex networks of only 2 components ([Valdeolivas et al.](https://doi.org/10.1093/bioinformatics/bty637)), and heterogeneous-multiplex networks of an arbitrary number of components ([Baptista et al.](https://doi.org/10.1038/s42005-022-00937-9)). AMEND implements a generalized version of RWR (slightly different than that of Baptista _et al._) and so can accommodate these heterogeneous/multiplex networks. If the user has a heterogeneous network with omics data that they would like to analyze with AMEND, they must specify `heterogeneous = TRUE`, along with the following arguments: `jump.prob`, and `net.weight`. For multiplex networks, the user must specify `multiplex = TRUE` along with `switch.layer.prob` and `layer.weight`.

### Monoplex-heterogeneous Network

The next three sections will illustrate examples of AMEND with these more complex networks. The first example focuses on a monoplex-heterogeneous network consisting of proteins and metabolites (or chemicals).

The code chunk below will create edge lists for the PPI, metabolite-metabolite interaction (MMI), and bipartite networks. Random data is generated from a standard normal distribution, representing log fold changes. It is important to note the naming scheme that has been used. I have appended an identifier for each component ('prot' and 'meta') to the ends of each node name, separated by '|'. This is so that the algorithm can identify the component to which each node belongs. 


```r
file_paths = c("/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/10090.protein.links.v11.0.txt.gz",
                 "/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/chemical_chemical.links.detailed.v5.0.tsv.gz",
                 "/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/10090.protein_chemical.links.v5.0.tsv.gz")
# Protein-protein interactions
ppi = data.table::fread(file = file_paths[1],
                          header = TRUE) %>%
    dplyr::filter(combined_score >= 800) %>%
    dplyr::rename(node1 = protein1,
                  node2 = protein2) %>%
    dplyr::mutate(node1 = paste0(node1, "|prot"),
                  node2 = paste0(node2, "|prot"),
                  combined_score = combined_score / 1000) %>%
    as.matrix()
# Unique protein names
uniq.prot = unique(extract_string2(c(ppi[,1], ppi[,2]), "\\|", 1))

# Metabolite-metabolite interactions
mmi = data.table::fread(file = file_paths[2],
                          header = TRUE) %>%
    dplyr::filter(combined_score >= 800) %>%
    dplyr::select(chemical1, chemical2, combined_score) %>%
    dplyr::rename(node1 = chemical1,
                  node2 = chemical2) %>%
    dplyr::mutate(node1 = paste0(node1, "|meta"),
                  node2 = paste0(node2, "|meta"),
                  combined_score = combined_score / 1000) %>%
    as.matrix()
# Getting a smaller subnetwork from this very large metabolite network
g.meta = igraph::graph_from_edgelist(mmi[,1:2], directed=FALSE)
E(g.meta)$weight = as.numeric(mmi[,3])
g.meta = igraph::simplify(graph = g.meta, edge.attr.comb = list(weight = "min"))
set.seed(55)
clust = igraph::cluster_louvain(graph = g.meta)
c.tbl = sort(table(clust$membership), decreasing = TRUE)
clust.id = as.numeric(names(c.tbl)[3])
subg.meta = igraph::induced_subgraph(graph = g.meta, 
                                     vids = which(clust$membership %in% clust.id))
if(!is_connected(subg.meta)) subg.meta = largest_connected_component(subg.meta)
mmi = as_edgelist(subg.meta)
mmi = cbind(mmi, E(subg.meta)$weight)
uniq.meta = unique(extract_string2(c(mmi[,1], mmi[,2]), "\\|", 1))

# Bipartite interactions 
bp = data.table::fread(file = file_paths[3],
                         header = TRUE) %>%
    dplyr::filter(combined_score >= 800) %>%
    dplyr::filter(protein %in% uniq.prot,
                  chemical %in% uniq.meta) %>%
    dplyr::rename(node1 = chemical,
                  node2 = protein) %>%
    dplyr::mutate(node1 = paste0(node1, "|meta"),
                  node2 = paste0(node2, "|prot"),
                  combined_score = combined_score / 1000) %>%
    as.matrix()

edgelists = list(prot = ppi, meta = mmi, "prot;meta" = bp)

# Creating random data 
data.list.input = vector("list", 2)
names(data.list.input) = c("prot", "meta")
for(i in seq_along(data.list.input)){
  uniq.names = extract_string2(unique(c(edgelists[[i]][,1], edgelists[[i]][,2])), "\\|", 1)
  data.list.input[[i]] = rnorm(n = length(uniq.names), mean = 0, sd = 1) # shift_scale or exp
  names(data.list.input[[i]]) = uniq.names
}
# Setting heterogeneous parameters
net.weight = c(prot = 0.5, meta = 0.5)
jump.prob = c(prot = 0.7, meta = 0.3)

# FUN and FUN.params
FUN = list(prot = "shift_scale", meta = function(x, k) abs(x) * k)
FUN.params = list(prot = list(DOI = 1, w = 0.5), meta = list(k = 1.2))
```

Next, we illustrate how to use `create_integrated_graph()`, which will merge common nodes between multiplex layers and merge different components using the provided bipartite connections. The edge lists may not give a connected graph, so we specify `lcc=TRUE` to return the **l**argest **c**onnected **c**omponent. For `run_AMEND()`, we specify an approximate final module size of 50, with degree normalization for the construction of the transition matrix. It is not necessary to run `create_integrated_graph()` before `run_AMEND`, since the former is called within the latter to create a single network object on which to run the algorithm. So, the edge lists can be input directly into `run_AMEND()`. If the network is heterogeneous and the network input is in list format, there must be a list element that corresponds to the bipartite connections between the different components. The naming scheme to denote bipartite graphs must follow 'component1;component2'. In this example, as seen below, the bipartite graph is named 'prot;meta' to denote that this list element contains proteins, metabolites, and connections between them. Node names in these bipartite graphs must be appended with their correct component before input into `run_AMEND()`. 


```r
names(edgelists)
#> [1] "prot"      "meta"      "prot;meta"

g.tmp = create_integrated_graph(edge_list = edgelists, data = data.list.input, node_type = NULL, 
                            brw.attr = NULL, FUN = FUN, FUN.params = FUN.params, 
                            heterogeneous = TRUE, multiplex = FALSE, lcc = TRUE)
g.tmp
#> IGRAPH 8666371 UNW- 16050 364777 -- 
#> + attr: name (v/c), node_type (v/c), pre.seed.values (v/n), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from 8666371 (vertex names):
#>  [1] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000017460|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000039107|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000052894|prot
#>  [4] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000025842|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000045335|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000126191|prot
#>  [7] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000093978|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000096847|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000040847|prot
#> [10] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000066822|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000093297|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000076155|prot
#> [13] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000052444|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000052581|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000077611|prot
#> [16] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000053489|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000110563|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000028883|prot
#> [19] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000053700|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000045911|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000085630|prot
#> [22] 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000137518|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000047586|prot 10090.ENSMUSP00000000001|prot--10090.ENSMUSP00000068731|prot
#> + ... omitted several edges
table(V(g.tmp)$node_type)
#> 
#>  meta  prot 
#>  2956 13094

subnet = run_AMEND(edge_list = edgelists, n = 50, data = data.list.input, node_type = NULL, 
                   brw.attr = NULL, FUN = FUN, FUN.params = FUN.params, 
                   heterogeneous = TRUE, multiplex = FALSE, normalize = "degree", 
                   jump.prob = jump.prob, net.weight = net.weight, verbose = TRUE)
#> Starting filtering rate: 0.6424
#> Iteration: 1
#> Iteration: 2
#> Iteration: 3
#> Iteration: 4
#> Iteration: 5
#> Iteration: 6
#> Iteration: 7
#> Iteration: 8
#> Iteration: 9
#> Iteration: 10
#> Iteration: 11
#> Iteration: 12
#> *** Converged! *** ID=1
subnet$module
#> IGRAPH e9d78b7 UNW- 66 102 -- 
#> + attr: name (v/c), node_type (v/c), pre.seed.values (v/n), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from e9d78b7 (vertex names):
#>  [1] CIDs00002519|meta--CIDs13993178|meta             CIDs00002519|meta--CIDs00016741|meta             CIDs13993178|meta--CIDs00016741|meta            
#>  [4] CIDs00002519|meta--CIDs00005971|meta             CIDs13993178|meta--CIDs00005971|meta             CIDs00016741|meta--CIDs00005971|meta            
#>  [7] CIDs00002519|meta--CIDs00091429|meta             CIDs13993178|meta--CIDs00091429|meta             CIDs00016741|meta--CIDs00091429|meta            
#> [10] CIDs00005971|meta--CIDs00091429|meta             CIDs00002818|meta--CIDs00002726|meta             CIDs00172197|meta--CIDs00002162|meta            
#> [13] CIDs03035905|meta--CIDs00003615|meta             CIDs00003615|meta--CIDs00041376|meta             CIDs00006041|meta--CIDs00006081|meta            
#> [16] CIDs00104849|meta--CIDs09821569|meta             CIDs00104849|meta--CIDs06321351|meta             CIDs05311444|meta--CIDs00001104|meta            
#> [19] CIDs00172197|meta--CIDs00123805|meta             CIDs00006041|meta--CIDs00189460|meta             CIDs00104849|meta--CIDs00002185|meta            
#> [22] CIDs00001204|meta--CIDs57226405|meta             CIDs00104849|meta--CIDs03086156|meta             CIDs09821569|meta--CIDs03086156|meta            
#> + ... omitted several edges
table(V(subnet$module)$node_type)
#> 
#> meta prot 
#>   29   37
```

### Multiplex-homogeneous Network

The code chunk below will create a list of adjacency matrices for 3 different layers of a PPI network, which may represent PPI networks containing distinct edge types, or they may represent the same network but the data that will be diffused on each layer will be different. For this example, the latter is the case. Random data is sampled from {0,1}, with 1's representing significantly up- or down-regulated genes. The different layers are simulated by taking different clusters of the PPI network after running the Louvain clustering algorithm. In order to be able to locate a node in a specific component and layer, each node name needs to be appended with '|component_layer'. In this case, each node is appended with either '|prot_1', '|prot_2', or '|prot_3', where 'prot' indicates the node type, and '1', '2', and '3' indicate the layer. If the network input is in list format, the component/layer information does not need to be appended to node names; the list names can provide this information and the algorithm will automatically append this info. This is the case for the following example.


```r
file_paths = c("/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/10090.protein.links.v11.0.txt.gz")
ppi = data.table::fread(file = file_paths[1],
                          header = TRUE) %>%
    dplyr::filter(combined_score >= 800) %>%
    dplyr::rename(node1 = protein1,
                  node2 = protein2) %>%
    dplyr::mutate(combined_score = combined_score / 1000) %>%
    as.matrix()
g.prot = igraph::graph_from_edgelist(ppi[,1:2], directed=FALSE)
E(g.prot)$weight = as.numeric(ppi[,3])
g.prot = igraph::simplify(graph = g.prot, edge.attr.comb = list(weight = "min"))
if(!igraph::is_connected(g.prot)) g.prot = largest_connected_component(g.prot)

# Creating multiplex component
set.seed(305)
list.of.adjmats = vector("list", 3); names(list.of.adjmats) = paste(rep("prot", 3), 1:3, sep = "_")
# Split PPIN into layers for transcriptomic, proteomic, and phospho-proteomic data
clusts = igraph::cluster_louvain(graph = g.prot) # Louvain method for getting clusters
k = 1 # Include k-nearest neighbors
for(i in 1:3){
  t.ids = which(clusts$membership == i)
  t.ids = unique(as.numeric(unlist(igraph::neighborhood(graph = g.prot, order = k, nodes = t.ids))))
  tmp = igraph::induced_subgraph(g.prot, t.ids)
  tmp = largest_connected_component(tmp)
  list.of.adjmats[[i]] = igraph::as_adjacency_matrix(tmp, attr = "weight", sparse = T)
}

# Create object for 'data' argument
data.list.input = vector("list", 3)
names(data.list.input) = c("prot_1", "prot_2", "prot_3")
for(i in seq_along(data.list.input)){
  data.list.input[[i]] = sample(x = c(0,1), size = nrow(list.of.adjmats[[i]]), 
                                replace = T, prob = c(0.9, 0.1)) # binary
  names(data.list.input[[i]]) = rownames(list.of.adjmats[[i]])
}

# Setting multiplex parameters
layer.weight = list(prot = c(prot_1 = 0.4, prot_2 = 0.3, prot_3 = 0.3))
switch.layer.prob = list(prot = c(prot_1 = 0.4, prot_2 = 0.5, prot_3 = 0.5))
```

Below, we create an integrated graph from the separate multiplex layers. We also use `run_AMEND()` with the list of multiplex layer adjacency matrices, using simulated binary data. We set `normalize="modified_degree"` and `k=0.5` to mitigate the influence of degree on diffusion scores. 


```r
g.tmp = create_integrated_graph(adj_matrix = list.of.adjmats, data = data.list.input, node_type = NULL, 
                            brw.attr = NULL, FUN = "binary", FUN.params = NULL, 
                            heterogeneous = FALSE, multiplex = TRUE, lcc = TRUE)
g.tmp
#> IGRAPH e40eab1 UNW- 5877 221267 -- 
#> + attr: name (v/c), node_type (v/c), pre.seed.values (v/n), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from e40eab1 (vertex names):
#>  [1] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000000153|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000000574|prot_1
#>  [3] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000001652|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000004076|prot_1
#>  [5] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000004480|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000005406|prot_1
#>  [7] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000005671|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000006544|prot_1
#>  [9] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000010205|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000017455|prot_1
#> [11] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000017460|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000019064|prot_1
#> [13] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000019071|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000019074|prot_1
#> [15] 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000019266|prot_1 10090.ENSMUSP00000000001|prot_1--10090.ENSMUSP00000020706|prot_1
#> + ... omitted several edges
table(V(g.tmp)$node_type)
#> 
#> prot_1 prot_2 prot_3 
#>   2303   2478   1096

subnet = run_AMEND(adj_matrix = list.of.adjmats, n = 100, data = data.list.input, node_type = NULL, 
                   brw.attr = NULL, FUN = "binary", FUN.params = NULL, heterogeneous = FALSE, 
                   multiplex = TRUE, normalize = "modified_degree", k = 0.5, 
                   switch.layer.prob = switch.layer.prob, layer.weight = layer.weight, verbose = TRUE)
#> Starting filtering rate: 0.5227
#> Iteration: 1
#> Iteration: 2
#> Iteration: 3
#> Iteration: 4
#> Iteration: 5
#> Iteration: 6
#> Iteration: 7
#> Iteration: 8
#> Iteration: 9
#> Iteration: 10
#> Iteration: 11
#> Iteration: 12
#> Iteration: 13
#> Iteration: 14
#> Iteration: 15
#> Iteration: 16
#> Iteration: 17
#> Iteration: 18
#> Iteration: 19
#> Iteration: 20
#> Iteration: 21
#> Iteration: 22
#> Iteration: 23
#> *** Converged! *** ID=1
subnet$module
#> IGRAPH 638c003 UNW- 111 862 -- 
#> + attr: name (v/c), node_type (v/c), pre.seed.values (v/n), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from 638c003 (vertex names):
#>  [1] 10090.ENSMUSP00000019064|prot_1--10090.ENSMUSP00000023959|prot_1 10090.ENSMUSP00000019064|prot_1--10090.ENSMUSP00000027440|prot_1
#>  [3] 10090.ENSMUSP00000023959|prot_1--10090.ENSMUSP00000027440|prot_1 10090.ENSMUSP00000019064|prot_1--10090.ENSMUSP00000028233|prot_1
#>  [5] 10090.ENSMUSP00000023959|prot_1--10090.ENSMUSP00000028233|prot_1 10090.ENSMUSP00000027440|prot_1--10090.ENSMUSP00000028233|prot_1
#>  [7] 10090.ENSMUSP00000019064|prot_1--10090.ENSMUSP00000028883|prot_1 10090.ENSMUSP00000023959|prot_1--10090.ENSMUSP00000028883|prot_1
#>  [9] 10090.ENSMUSP00000027440|prot_1--10090.ENSMUSP00000028883|prot_1 10090.ENSMUSP00000028233|prot_1--10090.ENSMUSP00000028883|prot_1
#> [11] 10090.ENSMUSP00000019064|prot_1--10090.ENSMUSP00000029326|prot_1 10090.ENSMUSP00000023959|prot_1--10090.ENSMUSP00000029326|prot_1
#> [13] 10090.ENSMUSP00000027440|prot_1--10090.ENSMUSP00000029326|prot_1 10090.ENSMUSP00000028233|prot_1--10090.ENSMUSP00000029326|prot_1
#> [15] 10090.ENSMUSP00000028883|prot_1--10090.ENSMUSP00000029326|prot_1 10090.ENSMUSP00000019064|prot_1--10090.ENSMUSP00000029633|prot_1
#> + ... omitted several edges
table(V(subnet$module)$node_type)
#> 
#> prot_1 prot_2 prot_3 
#>     51     33     27
```

### Multiplex-heterogeneous Network

This is the most complex example of this vignette, where we are creating a multiplex-heterogeneous network. Below, we create a PPI, MMI, and bipartite network. Then, using the Louvain clustering algorithm, we simulate multiplex layers for the PPI network. These 3 layers will be used to diffuse 3 different datasets on the same interaction network, allowing for data integration and for controlled cross-talk between each layer using the `switch.layer.prob` parameter. The data used in this example comes from a Uniform(0,1) distribution, representing p-values from some omic experiment.


```r
file_paths = c("/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/10090.protein.links.v11.0.txt.gz",
                 "/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/chemical_chemical.links.detailed.v5.0.tsv.gz",
                 "/Users/samboyd/Documents/GRA/Network Analysis/AMEND/R_package/10090.protein_chemical.links.v5.0.tsv.gz")
ppi = data.table::fread(file = file_paths[1],
                          header = TRUE) %>%
    dplyr::filter(combined_score >= 800) %>%
    dplyr::rename(node1 = protein1,
                  node2 = protein2) %>%
    dplyr::mutate(node1 = paste0(node1, "|prot"),
                  node2 = paste0(node2, "|prot"),
                  combined_score = combined_score / 1000) %>%
    as.matrix()
g.prot = igraph::graph_from_edgelist(ppi[,1:2], directed=FALSE)
E(g.prot)$weight = as.numeric(ppi[,3])
g.prot = igraph::simplify(graph = g.prot)
uniq.prot = unique(extract_string2(c(ppi[,1], ppi[,2]), "\\|", 1))

mmi = data.table::fread(file = file_paths[2],
                          header = TRUE) %>%
    dplyr::filter(combined_score >= 800) %>%
    dplyr::select(chemical1, chemical2, combined_score) %>%
    dplyr::rename(node1 = chemical1,
                  node2 = chemical2) %>%
    dplyr::mutate(node1 = paste0(node1, "|meta"),
                  node2 = paste0(node2, "|meta"),
                  combined_score = combined_score / 1000) %>%
    as.matrix()
g.meta = igraph::graph_from_edgelist(mmi[,1:2], directed=FALSE)
E(g.meta)$weight = as.numeric(mmi[,3])
g.meta = igraph::simplify(graph = g.meta, edge.attr.comb = list(weight = "min"))
set.seed(55)
clust = igraph::cluster_louvain(graph = g.meta)
c.tbl = sort(table(clust$membership), decreasing = TRUE)
clust.id = as.numeric(names(c.tbl)[3])
subg.meta = igraph::induced_subgraph(graph = g.meta, vids = which(clust$membership %in% clust.id))
if(!is_connected(subg.meta)) subg.meta = largest_connected_component(subg.meta)
mmi = as_edgelist(subg.meta)
mmi = cbind(mmi, E(subg.meta)$weight)
uniq.meta = unique(extract_string2(c(mmi[,1], mmi[,2]), "\\|", 1))

bp = data.table::fread(file = file_paths[3],
                         header = TRUE) %>%
    dplyr::filter(combined_score >= 800) %>%
    dplyr::filter(protein %in% uniq.prot,
                  chemical %in% uniq.meta) %>%
    dplyr::rename(node1 = chemical,
                  node2 = protein) %>%
    dplyr::mutate(node1 = paste0(node1, "|meta"),
                  node2 = paste0(node2, "|prot"),
                  combined_score = combined_score / 1000) %>%
    as.matrix()

el = rbind(ppi, mmi, bp)

g = igraph::graph_from_edgelist(el = el[,1:2], directed = FALSE)
E(g)$weight = as.numeric(el[,3])
g = igraph::simplify(graph = g, edge.attr.comb = list(weight = "min"))
if(!is_connected(g)) g = largest_connected_component(g)

# Creating multiplex component
g.prot = igraph::induced_subgraph(g, which(extract_string2(V(g)$name, "\\|", 2) == "prot"))
V(g.prot)$name = extract_string2(V(g.prot)$name, "\\|", 1)
if(!igraph::is_connected(g.prot)) g.prot = largest_connected_component(g.prot)
g.tmp = vector("list", 3); names(g.tmp) = paste(rep("prot", 3), 1:3, sep = "_")
# Split PPIN into layers for transcriptomic, proteomic, and phospho-proteomic data
clusts = igraph::cluster_louvain(graph = g.prot) # Louvain method for getting clusters
k = 1 # Include k-nearest neighbors
for(i in 1:3){
  t.ids = which(clusts$membership == i)
  t.ids = unique(as.numeric(unlist(igraph::neighborhood(graph = g.prot, order = k, nodes = t.ids))))
  tmp = igraph::induced_subgraph(g.prot, t.ids)
  g.tmp[[i]] = largest_connected_component(tmp)
}

g.meta = igraph::induced_subgraph(g, grep(pattern = "\\|meta", x = V(g)$name))
if(!igraph::is_connected(g.meta)) g.meta = largest_connected_component(g.meta)

bp.node = logical(vcount(g))
for(i in seq_along(bp.node)){
  nei = as_ids(neighbors(g, i, mode="all"))
  bp.node[i] = all(c("prot", "meta") %in% extract_string2(nei, "\\|", 2))
}

g.bp = igraph::induced_subgraph(g, which(bp.node))

list.of.graphs = c(g.tmp, meta = list(g.meta), "prot;meta" = list(g.bp))

# Create data vertex attributes, called 'scores'
v.attr.name = "scores"
node.types = c("prot_1", "prot_2", "prot_3", "meta")
for(i in seq_along(node.types)){
  igraph::vertex_attr(list.of.graphs[[node.types[i]]], v.attr.name) = runif(vcount(list.of.graphs[[node.types[i]]])) # p-value
}

# Setting multiplex/heterogeneous parameters
layer.weight = list(prot = rep(1/3, 3))
switch.layer.prob = list(prot = c(prot_1 = 0.5, prot_2 = 0.2, prot_3 = 0.8))
net.weight = c(prot = 0.5, meta = 0.5)
jump.prob = c(prot = 0.5, meta = 0.3)
```

Again, we illustrate the use of `create_integrated_graph()` to construct a graph that combines the different components and multiplex layers. We also use `run_AMEND()` using the list of igraph objects. The `FUN = "p_value"` argument will take the negative log transform of the input `data`. Alternatively, we could specify a named list for `FUN` if we wanted to use different functions for the different components of the network. Equal weight is given to the seed values of each component; however, the jump probability (`jump.prob`) for the MMI component is 0.3, compared to 0.5 for the PPI component. Therefore, the random walker will be less likely to jump from the MMI component, which will result in larger scores for those nodes. A similar story can be told for `switch.layer.prob`; the lower the values for these parameters, the less likely the random walker will leave that layer or component, resulting in larger node scores.


```r
g.tmp = create_integrated_graph(graph = list.of.graphs, data = "scores", node_type = NULL, 
                                brw.attr = NULL, FUN = FUN, FUN.params = FUN.params, 
                                heterogeneous = TRUE, multiplex = TRUE)
g.tmp
#> IGRAPH 6f8546c UNW- 8876 275266 -- 
#> + attr: name (v/c), scores (v/n), node_type (v/c), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from 6f8546c (vertex names):
#>  [1] CIDs91758271|meta--CIDs00004192|meta CIDs91758271|meta--CIDs05311068|meta CIDs00004192|meta--CIDs05311068|meta CIDs00004192|meta--CIDs00002118|meta CIDs00004192|meta--CIDs00003821|meta
#>  [6] CIDs00004192|meta--CIDs00198290|meta CIDs00004192|meta--CIDs00003373|meta CIDs00004192|meta--CIDs05288826|meta CIDs00004192|meta--CIDs00174174|meta CIDs00004192|meta--CIDs00003676|meta
#> [11] CIDs00004192|meta--CIDs00134664|meta CIDs00004192|meta--CIDs00003345|meta CIDs00004192|meta--CIDs00107917|meta CIDs00004192|meta--CIDs00004058|meta CIDs00004192|meta--CIDs00004943|meta
#> [16] CIDs00004192|meta--CIDs00060814|meta CIDs00004192|meta--CIDs00003016|meta CIDs00004192|meta--CIDs00041693|meta CIDs00004192|meta--CIDs00004737|meta CIDs00004192|meta--CIDs00051263|meta
#> [21] CIDs00004192|meta--CIDs00039764|meta CIDs00004192|meta--CIDs00000948|meta CIDs00004192|meta--CIDs03000715|meta CIDs00004192|meta--CIDs00003763|meta CIDs00004192|meta--CIDs00003494|meta
#> [26] CIDs00004192|meta--CIDs00005206|meta CIDs00004192|meta--CIDs00003393|meta CIDs00004192|meta--CIDs00003958|meta CIDs00004192|meta--CIDs00005556|meta CIDs00004192|meta--CIDs00042113|meta
#> [31] CIDs00004192|meta--CIDs00015139|meta
#> + ... omitted several edges
table(V(g.tmp)$node_type)
#> 
#>   meta prot_1 prot_2 prot_3 
#>   2956   2266   2558   1096

subnet = run_AMEND(graph = list.of.graphs, n = 100, data = "scores", node_type = NULL, brw.attr = NULL,
                     FUN = "p_value", FUN.params = NULL, heterogeneous = TRUE, multiplex = TRUE,
                     normalize = "degree", jump.prob = jump.prob, 
                     net.weight = net.weight, switch.layer.prob = switch.layer.prob, 
                     layer.weight = layer.weight, verbose = TRUE)
#> Warning in run_AMEND(graph = list.of.graphs, n = 100, data = "scores", node_type = NULL, : No layer names given in layer.weight[[1]]. Assuming layer order matches order of input for
#> graph/adj_matrix/edge_list.
#> Starting filtering rate: 0.5517
#> Iteration: 1
#> Iteration: 2
#> Iteration: 3
#> Iteration: 4
#> Iteration: 5
#> Iteration: 6
#> Iteration: 7
#> Iteration: 8
#> Iteration: 9
#> Iteration: 10
#> Iteration: 11
#> Iteration: 12
#> Iteration: 13
#> Iteration: 14
#> Iteration: 15
#> Iteration: 16
#> Iteration: 17
#> Iteration: 18
#> *** Converged! *** ID=1
subnet$module
#> IGRAPH 7429b25 UNW- 126 420 -- 
#> + attr: name (v/c), scores (v/n), node_type (v/c), brw.values (v/n), seeds (v/n), Z (v/n), weight (e/n)
#> + edges from 7429b25 (vertex names):
#>  [1] CIDs00004192|meta--CIDs05311068|meta CIDs00004192|meta--CIDs00002118|meta CIDs00004192|meta--CIDs00003821|meta CIDs00004192|meta--CIDs00198290|meta CIDs00003821|meta--CIDs00198290|meta
#>  [6] CIDs00004192|meta--CIDs05288826|meta CIDs00004192|meta--CIDs00134664|meta CIDs00002118|meta--CIDs00134664|meta CIDs00004192|meta--CIDs00004943|meta CIDs05311068|meta--CIDs00004943|meta
#> [11] CIDs00003821|meta--CIDs00004943|meta CIDs00198290|meta--CIDs00004943|meta CIDs00004192|meta--CIDs00039764|meta CIDs00004943|meta--CIDs00039764|meta CIDs00004192|meta--CIDs00003494|meta
#> [16] CIDs00004943|meta--CIDs00003494|meta CIDs00039764|meta--CIDs00003494|meta CIDs00004192|meta--CIDs00003958|meta CIDs00002118|meta--CIDs00003958|meta CIDs00134664|meta--CIDs00003958|meta
#> [21] CIDs00004192|meta--CIDs00005556|meta CIDs00002118|meta--CIDs00005556|meta CIDs00134664|meta--CIDs00005556|meta CIDs00003958|meta--CIDs00005556|meta CIDs00004192|meta--CIDs00042113|meta
#> [26] CIDs00004943|meta--CIDs00042113|meta CIDs00004192|meta--CIDs00015139|meta CIDs05311068|meta--CIDs00002803|meta CIDs05288826|meta--CIDs00002803|meta CIDs00002118|meta--CIDs00162244|meta
#> [31] CIDs00003821|meta--CIDs00180081|meta CIDs00003821|meta--CIDs00001207|meta CIDs00003821|meta--CIDs06604887|meta CIDs00003821|meta--CIDs00123767|meta CIDs00198290|meta--CIDs00104845|meta
#> [36] CIDs00004943|meta--CIDs00104845|meta CIDs00004266|meta--CIDs00010237|meta CIDs05288826|meta--CIDs00000681|meta CIDs00180081|meta--CIDs00000681|meta CIDs00001207|meta--CIDs00000681|meta
#> + ... omitted several edges
table(V(subnet$module)$node_type)
#> 
#>   meta prot_1 prot_2 prot_3 
#>     38     13     12     63
```

## Mitigating Degree Bias

PPI networks have largely been recognized to suffer from a node degree bias arising from technical and study biases associated with PPI experiments. Many experimental approaches for ascertaining PPIs use a bait and prey paradigm. The degree of a protein in a PPI network (the number of proteins that protein has been shown to interact with) is highly dependent on the number of times it has been used as bait in PPI experiments. The degree also depends on the general research interest that exists for a protein; some proteins are implicated in disease areas that benefit from more active research as compared to others. This causes the degrees of some proteins to be inflated compared to others, which manifests itself in higher diffusion scores for those proteins with inflated degree. 

Most active module identification methods do not address degree bias, although several approaches have been developed to deal with the issue. Many are permutation-based involving permuations of the data or random networks. Others adjust diffusion scores according to node centrality. Still others attempt to address degree bias in the creation of the transition matrix prior to any network diffusion method. Notably, the developers of NetCore [Barel et al.](https://doi.org/10.1093/nar/gkaa639) use node coreness (rather than degree) to create the transition matrix and thus claim to address degree bias, where coreness is a global measure of node connectivity (whereas degree is a local measure). However, upon reflection, this claim seems to be incorrect. In the core-normalized transition matrix $M=(m_{ij})$, the probability of moving from node $j$ to node $i$ (i.e., $Pr(j\rightarrow i)$) is $m_{ij}=\frac{k_i}{\sum_{l\in S_j}k_l}$, where $k_i$ is the coreness of node $i$ and $S_j$ is the set of neighbors of node $j$. Therefore, the probability of moving to node $i$ depends on its coreness, which is a measure of its connectivity and is highly correlated with its degree. In the context of RWR, a random walker may be _more_ likely to move to a node that is subject to degree bias (i.e., has an inflated degree, and by correlation, an inflated coreness), resulting in a larger diffusion score and an exacerbation of the degree bias issue. Therefore, AMEND provides the option `normalize = degree` to create the transition matrix, where $Pr(j\rightarrow i)$ does _not_ depend on the degree of node $i$. An alternative is `normalize = modified_degree`, which first creates a modified adjacency matrix that penalizes edge weights in proportion to the product of the degrees of its adjacent nodes and then column-normalizes this modified adjacency matrix.

<!---
A procedure currently in development wih the goal of mitigating degree bias is called _bistochastic scaling_, which is applied directly to the transition matrix and globally attenuates the influence that degree has on diffusion scores. Assuming a left stochastic transition matrix, this procedure transforms the input transition matrix such that it is approximately bistochastic (doubly stochastic). As this is still in development, this feature isn't currently available to users. More details will be forthcoming as the methodology matures.
--->



